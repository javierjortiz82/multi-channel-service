# =============================================================================
# Multi-Channel Service - Project Expertise
# =============================================================================
# Este archivo contiene el conocimiento acumulado del proyecto.
# Claude lee esta expertise al inicio de cada sesión.
# Actualizado: 2026-01-29
# =============================================================================

project:
  name: multi-channel-service
  description: Telegram bot con procesamiento inteligente de mensajes (texto, audio, imagen)
  language: Python 3.12
  framework: aiogram (Telegram Bot API)
  package_manager: UV (10x más rápido que pip)

# =============================================================================
# Arquitectura
# =============================================================================
architecture:
  pattern: Microservicios con API Gateway

  flow:
    - Telegram → API Gateway (público) → Cloud Run (privado/IAM) → Backend Services

  services:
    multi-channel-service:
      url: https://multi-channel-service-4k3haexkga-uc.a.run.app
      gateway: https://multi-channel-gateway-vq1gs9i.uc.gateway.dev
      role: Orquestador de mensajes de Telegram

    nlp-service:
      url: https://nlp-service-4k3haexkga-uc.a.run.app
      role: Procesamiento de lenguaje natural con Gemini 2.0

    asr-service:
      url: https://asr-service-4k3haexkga-uc.a.run.app
      role: Speech-to-Text con Google Cloud STT v2
      auto_detect_languages: [es-ES, en-US, ar-SA]

    ocr-service:
      url: https://ocr-service-4k3haexkga-uc.a.run.app
      role: Extracción de texto de imágenes

  message_routing:
    TEXT: NLP Service
    VOICE/AUDIO: ASR Service → NLP Service
    PHOTO: OCR Service → NLP Service

  escalation_flow:
    description: "Flujo de escalación a agentes humanos (2026-01-29)"
    trigger: "NLP Service detecta emociones negativas o solicitud de humano"
    flow:
      - "Usuario envía mensaje con emoción negativa"
      - "NLP Service analiza sentimiento (via prompt sales.j2)"
      - "Si 3+ emociones negativas → NLP llama escalate_to_human() via MCP"
      - "MCP Server crea registro en test.escalations"
      - "Bot responde: 'Voy a conectarte con un especialista...'"
      - "Dashboard API muestra escalación pendiente"
      - "Agente humano reclama y resuelve"
    immediate_triggers:
      - customer_request: "quiero hablar con una persona"
      - system_error: "error del sistema", "no funciona"
      - payment_issue: "cobro duplicado", "problema con pago"

# =============================================================================
# Archivos Clave
# =============================================================================
key_files:
  message_processor: src/telegram_bot/services/message_processor.py
  internal_client: src/telegram_bot/services/internal_client.py
  input_classifier: src/telegram_bot/services/input_classifier.py
  dockerfile: deploy/Dockerfile.cloudrun
  cloudbuild: cloudbuild.yaml

# =============================================================================
# GCP Configuration
# =============================================================================
gcp:
  project_id: gen-lang-client-0329024102
  region: us-central1
  service_account: orchestrator-sa

  secrets:
    - telegram-bot-token
    - webhook-secret
    - database-url

  apis_required:
    - run.googleapis.com
    - cloudbuild.googleapis.com
    - speech.googleapis.com
    - secretmanager.googleapis.com

# =============================================================================
# Webhook Configuration (CRÍTICO)
# =============================================================================
webhook:
  critical_note: |
    El webhook de Telegram DEBE apuntar al API Gateway, NO a Cloud Run directamente.
    Cloud Run está protegido por IAM (política de organización impide acceso público).

  url: https://multi-channel-gateway-vq1gs9i.uc.gateway.dev/webhook

  setup_command: |
    BOT_TOKEN=$(gcloud secrets versions access latest --secret=telegram-bot-token)
    WEBHOOK_SECRET=$(gcloud secrets versions access latest --secret=webhook-secret)
    curl "https://api.telegram.org/bot${BOT_TOKEN}/setWebhook?url=https://multi-channel-gateway-vq1gs9i.uc.gateway.dev/webhook&secret_token=${WEBHOOK_SECRET}"

# =============================================================================
# Lecciones Aprendidas
# =============================================================================
lessons_learned:

  - id: asr_response_format
    date: 2026-01-16
    problem: "Audio siempre fallaba con 'No pude transcribir el audio'"
    root_cause: |
      El código buscaba asr_result.get("text") pero el ASR service
      retorna la transcripción en asr_result.get("data", {}).get("transcription")
    solution: |
      Cambiar el parsing de la respuesta ASR:
      - Incorrecto: asr_result.get("text", "")
      - Correcto: asr_result.get("data", {}).get("transcription", "")
    files_affected:
      - src/telegram_bot/services/message_processor.py
      - src/telegram_bot/services/internal_client.py

  - id: asr_language_detection
    date: 2026-01-16
    problem: "Audio en inglés fallaba cuando usuario tenía Telegram en español"
    root_cause: |
      Se pasaba message.from_user.language_code como language_hint al ASR.
      Esto forzaba al ASR a buscar solo en ese idioma.
    solution: |
      No pasar language_hint para que el ASR use auto-detección.
      El ASR auto-detecta entre: es-ES, en-US, ar-SA
    files_affected:
      - src/telegram_bot/services/message_processor.py

  - id: speech_api_disabled
    date: 2026-01-16
    problem: "ASR retornaba 500 Internal Server Error"
    root_cause: "Cloud Speech-to-Text API no estaba habilitada en el proyecto"
    solution: "gcloud services enable speech.googleapis.com --project=gen-lang-client-0329024102"

  - id: webhook_secret_required
    date: 2025-12-31
    problem: "Webhook retornaba 401 Unauthorized"
    root_cause: "Faltaba secret_token en la configuración del webhook"
    solution: "Incluir &secret_token=... en el setWebhook URL"

  - id: bant_proactive_questions
    date: 2026-01-28
    problem: "Sistema BANT solo reactivo, depende 100% del juicio del LLM"
    root_cause: |
      El bot esperaba a que Gemini decidiera llamar analyze_lead_bant().
      Sin preguntas proactivas, no recopilaba info BANT consistentemente.
    solution: |
      Agregadas preguntas BANT proactivas al template de ventas (sales.j2):
      - Timeline: "¿Para cuándo necesitarías los productos?"
      - Budget: "¿Cuál es tu presupuesto aproximado?"
      - Need: "¿Para cuántas personas necesitas el equipo?"
      - Authority: "¿Tú tomarás la decisión de compra?"
      Reglas: Una pregunta por mensaje, orden de prioridad, sin repetir
    files_affected:
      - nlp-service/app/templates/system_instructions/sales.j2

  - id: sentiment_escalation_system
    date: 2026-01-29
    problem: "Bot no escalaba apropiadamente con clientes frustrados"
    root_cause: |
      No había sistema de tracking de emociones negativas ni reglas claras
      de cuándo escalar a un humano.
    solution: |
      Implementación completa de sistema de escalación:

      1. Prompt (sales.j2): Sistema de 3-strikes
         - 1ra emoción negativa → Empatía + resolver
         - 2da emoción negativa → Disculpa + alternativa
         - 3ra emoción negativa → ESCALAR

      2. MCP Tool (escalate_to_human): Crea registro en BD
         - Guarda context (conversation_summary, last_message)
         - Vincula con BANT lead si existe
         - Asigna prioridad según reason

      3. Dashboard API: CRUD completo de escalaciones
         - Cola de pendientes ordenada por prioridad
         - Workflow: pending → assigned → in_progress → resolved

      Escalación inmediata (sin contar): customer_request, system_error, payment_issue
    files_affected:
      - nlp-service/app/templates/system_instructions/sales.j2
      - mcp-server/tools/sales/escalation.py
      - mcp-server/mcp_handlers/sales_handlers.py
      - mcp-server/sql/004_create_escalations_table.sql
      - dashboard_api/app/models/escalation.py
      - dashboard_api/app/services/escalation_service.py
      - dashboard_api/app/routers/escalations.py

  - id: conversation_memory_improvements
    date: 2026-01-29
    problem: "Bot no mantenía contexto adecuado entre mensajes"
    root_cause: |
      El sistema de memoria de conversación solo incluía mensajes del usuario
      (include_assistant=False), haciendo que el LLM no viera sus respuestas
      anteriores y tratara cada mensaje como aislado.
    solution: |
      Mejoras implementadas en NLP Service:

      1. Formato Estructurado XML:
         - Incluye tanto usuario como asistente
         - Tags: <conversation_history>, <turn role="user/assistant">
         - Timestamps relativos: "5m ago", "2h ago"

      2. Control por Tokens:
         - Límite de ~2000 tokens por historial
         - Trim automático de mensajes antiguos
         - Aumentado MAX_HISTORY_MESSAGES a 10

      3. Feature Flags para Rollback:
         - MEMORY_INCLUDE_ASSISTANT (default: true)
         - MEMORY_USE_STRUCTURED_FORMAT (default: true)
         - MEMORY_MAX_TOKENS (default: 2000)
         - MEMORY_SUMMARIZATION_ENABLED (default: false)

      4. Instrucción de Idioma:
         - Template actualizado con instrucción explícita
         - Responder en idioma del mensaje ACTUAL
         - Ignorar idiomas del historial

      5. Sistema de Resumen (preparado, deshabilitado):
         - ConversationSummarizer service
         - Tabla nlp_conversation_summaries
         - Trigger: 8+ mensajes
         - Gemini genera resumen de mensajes antiguos
    files_affected:
      - nlp-service/config/settings.py
      - nlp-service/app/services/conversation_memory.py
      - nlp-service/app/services/conversation_summarizer.py (nuevo)
      - nlp-service/app/templates/unified.j2
      - nlp-service/app/templates/_base/macros.j2
      - nlp-service/app/api/routes.py
      - nlp-service/app/db/database.py
    rollback_levels:
      - level_1: "MEMORY_SUMMARIZATION_ENABLED=false (solo resumen)"
      - level_2: "MEMORY_INCLUDE_ASSISTANT=false (solo usuario)"
      - level_3: "MEMORY_USE_STRUCTURED_FORMAT=false (legacy completo)"

# =============================================================================
# Patrones y Convenciones
# =============================================================================
patterns:

  commit_style:
    format: "conventional commits"
    examples:
      - "fix: correct ASR response parsing"
      - "feat: add auto-detection for audio language"
      - "docs: update webhook troubleshooting"
    co_author: "Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"

  code_quality:
    linter: ruff
    formatter: ruff format
    pre_deploy_validation: true
    command: "make deploy (incluye validación)"

  deployment:
    tool: Cloud Build
    config: cloudbuild.yaml
    quick_deploy: "make deploy-quick (sin validación)"
    full_deploy: "make deploy (con lint + format check)"

  logging:
    style: structlog
    format: "timestamp | level | message | key=value"

# =============================================================================
# Comandos Frecuentes
# =============================================================================
common_commands:
  deploy: "make deploy"
  deploy_quick: "make deploy-quick"
  logs: "make logs"
  logs_asr: "make logs-asr"
  logs_error: "make logs-error"
  health: "make health"
  webhook_status: "make webhook"
  webhook_reset: "make webhook-reset"
  format: "make format"
  lint: "make lint"

# =============================================================================
# Preferencias del Usuario
# =============================================================================
preferences:
  language: Spanish (comunicación), English (código/commits)
  deploy_style: Cloud Build via Makefile
  avoid:
    - No crear archivos nuevos innecesarios
    - No duplicar archivos (ej: model.py → models_simple.py)
  prefer:
    - Editar archivos existentes
    - Usar Makefile para operaciones comunes
    - Commits descriptivos con conventional commits
    - Revisar logs antes de diagnosticar

# =============================================================================
# Troubleshooting Quick Reference
# =============================================================================
troubleshooting:

  audio_not_transcribing:
    check:
      - "make logs-asr - Verificar errores del ASR"
      - "gcloud services list --enabled - Verificar speech.googleapis.com"
    common_causes:
      - API Speech-to-Text deshabilitada
      - language_hint incorrecto
      - Formato de respuesta parseado incorrectamente

  webhook_errors:
    404: "URL apunta a ngrok expirado → Reconfigurar con make webhook-reset"
    401: "Falta secret_token → Usar make webhook-reset (incluye secret)"
    403: "URL apunta a Cloud Run directo → Debe apuntar a API Gateway"

  deploy_failures:
    format_error: "make format && make deploy"
    auth_error: "gcloud auth login"
