# =============================================================================
# Multi-Channel Service - Project Expertise
# =============================================================================
# Este archivo contiene el conocimiento acumulado del proyecto.
# Claude lee esta expertise al inicio de cada sesión.
# Actualizado: 2026-01-18
# =============================================================================

project:
  name: multi-channel-service
  description: Telegram bot con procesamiento inteligente de mensajes (texto, audio, imagen)
  language: Python 3.12
  framework: aiogram (Telegram Bot API)
  package_manager: UV (10x más rápido que pip)

# =============================================================================
# Arquitectura
# =============================================================================
architecture:
  pattern: Microservicios con API Gateway

  flow:
    - Telegram → API Gateway (público) → Cloud Run (privado/IAM) → Backend Services

  services:
    multi-channel-service:
      url: https://multi-channel-service-4k3haexkga-uc.a.run.app
      gateway: https://multi-channel-gateway-vq1gs9i.uc.gateway.dev
      role: Orquestador de mensajes de Telegram

    nlp-service:
      url: https://nlp-service-4k3haexkga-uc.a.run.app
      role: Procesamiento de lenguaje natural con Gemini 2.0
      returns: |
        TextResponse {
          response: "texto de Gemini",
          products: [{sku, name, brand, price, description, category, image_url}] | null
        }

    asr-service:
      url: https://asr-service-4k3haexkga-uc.a.run.app
      role: Speech-to-Text con Google Cloud STT v2
      auto_detect_languages: [es-ES, en-US, ar-SA]

    ocr-service:
      url: https://ocr-service-4k3haexkga-uc.a.run.app
      role: Extracción de texto de imágenes

  message_routing:
    TEXT: NLP Service (Gemini auto-detects language)
    VOICE/AUDIO: ASR Service (auto-detect language) → NLP Service
    PHOTO: OCR Service → NLP Service

  product_flow:
    description: "Productos estructurados desde NLP para formato consistente"
    steps:
      - "User pregunta por productos → NLP Service"
      - "NLP llama MCP tools (fuzzy_search_smart) → productos DB"
      - "NLP extrae productos y los incluye en TextResponse.products"
      - "Multi-Channel recibe productos estructurados"
      - "Disponibles para: product cards, carousels, imágenes"
    note: |
      Gemini usa la macro product_format() para formato consistente en texto.
      Multi-Channel tiene format_nlp_products() para formateo adicional si necesario.

# =============================================================================
# Archivos Clave
# =============================================================================
key_files:
  message_processor: src/telegram_bot/services/message_processor.py
  internal_client: src/telegram_bot/services/internal_client.py
  input_classifier: src/telegram_bot/services/input_classifier.py
  message_handler: src/telegram_bot/bot/handlers/message_handler.py
  templates: src/telegram_bot/templates/  # Jinja2 templates for i18n
  dockerfile: deploy/Dockerfile.cloudrun
  cloudbuild: cloudbuild.yaml

# =============================================================================
# GCP Configuration
# =============================================================================
gcp:
  project_id: gen-lang-client-0329024102
  region: us-central1
  service_account: orchestrator-sa

  secrets:
    - telegram-bot-token
    - webhook-secret
    - database-url

  apis_required:
    - run.googleapis.com
    - cloudbuild.googleapis.com
    - speech.googleapis.com
    - secretmanager.googleapis.com

# =============================================================================
# Webhook Configuration (CRÍTICO)
# =============================================================================
webhook:
  critical_note: |
    El webhook de Telegram DEBE apuntar al API Gateway, NO a Cloud Run directamente.
    Cloud Run está protegido por IAM (política de organización impide acceso público).

  url: https://multi-channel-gateway-vq1gs9i.uc.gateway.dev/webhook

  setup_command: |
    BOT_TOKEN=$(gcloud secrets versions access latest --secret=telegram-bot-token)
    WEBHOOK_SECRET=$(gcloud secrets versions access latest --secret=webhook-secret)
    curl "https://api.telegram.org/bot${BOT_TOKEN}/setWebhook?url=https://multi-channel-gateway-vq1gs9i.uc.gateway.dev/webhook&secret_token=${WEBHOOK_SECRET}"

# =============================================================================
# Lecciones Aprendidas
# =============================================================================
lessons_learned:

  - id: asr_response_format
    date: 2026-01-16
    problem: "Audio siempre fallaba con 'No pude transcribir el audio'"
    root_cause: |
      El código buscaba asr_result.get("text") pero el ASR service
      retorna la transcripción en asr_result.get("data", {}).get("transcription")
    solution: |
      Cambiar el parsing de la respuesta ASR:
      - Incorrecto: asr_result.get("text", "")
      - Correcto: asr_result.get("data", {}).get("transcription", "")
    files_affected:
      - src/telegram_bot/services/message_processor.py
      - src/telegram_bot/services/internal_client.py

  - id: asr_language_detection
    date: 2026-01-16
    problem: "Audio en inglés fallaba cuando usuario tenía Telegram en español"
    root_cause: |
      Se pasaba message.from_user.language_code como language_hint al ASR.
      Esto forzaba al ASR a buscar solo en ese idioma.
    solution: |
      No pasar language_hint para que el ASR use auto-detección.
      El ASR auto-detecta entre: es-ES, en-US, ar-SA
    files_affected:
      - src/telegram_bot/services/message_processor.py

  - id: speech_api_disabled
    date: 2026-01-16
    problem: "ASR retornaba 500 Internal Server Error"
    root_cause: "Cloud Speech-to-Text API no estaba habilitada en el proyecto"
    solution: "gcloud services enable speech.googleapis.com --project=gen-lang-client-0329024102"

  - id: webhook_secret_required
    date: 2025-12-31
    problem: "Webhook retornaba 401 Unauthorized"
    root_cause: "Faltaba secret_token en la configuración del webhook"
    solution: "Incluir &secret_token=... en el setWebhook URL"

  - id: jinja2_templates_i18n
    date: 2026-01-18
    problem: "Strings hardcodeados en Python dificultaban mantenimiento e i18n"
    root_cause: |
      ERROR_MESSAGES dict con 60+ strings, START_MESSAGE/HELP_MESSAGE,
      prompts NLP, y formatos de producto todos hardcodeados en Python.
    solution: |
      Extraer todos los strings a templates Jinja2:
      - templates/messages/errors/{es,en,pt,fr,ar}.j2 - Errores i18n
      - templates/messages/commands/{start,help}.j2 - Comandos
      - templates/products/{card,text_list,carousel_caption,_macros}.j2
      - templates/prompts/document_analysis.j2 - NLP prompts
      Usar TemplateManager singleton con filtros: escape_html, format_price, format_percent, truncate_text
    files_affected:
      - src/telegram_bot/templates/__init__.py (nuevo)
      - src/telegram_bot/services/message_processor.py
      - src/telegram_bot/bot/handlers/message_handler.py
      - pyproject.toml (jinja2>=3.1.0)

  - id: text_language_detection
    date: 2026-01-18
    problem: "langdetect era redundante - Gemini ya auto-detecta idioma"
    root_cause: |
      langdetect fallaba para textos cortos (<10 chars), que son muy comunes en Telegram.
      Gemini 2.5 detecta automáticamente el idioma del input con 99%+ precisión.
      La detección local era redundante y agregaba complejidad sin beneficio real.
    solution: |
      Eliminar langdetect y confiar en Gemini para detección de idioma:
      - Gemini responde automáticamente en el idioma del input del usuario
      - Telegram language_code se usa solo como fallback para mensajes de error
      - Arquitectura simplificada: menos código, mejor mantenibilidad
      - Precisión mejorada para textos cortos (Gemini maneja "Hola", "Hi", etc.)
    files_affected:
      - pyproject.toml (removed langdetect)
      - src/telegram_bot/services/message_processor.py
      - src/telegram_bot/tests/test_message_processor.py

  - id: structured_product_response
    date: 2026-01-18
    problem: "Formato de productos inconsistente - Gemini formateaba libremente"
    root_cause: |
      El template agents/sales/base.j2 no incluía la macro product_format().
      Gemini decidía el formato de productos libremente en cada respuesta.
      Multi-Channel no tenía acceso a datos estructurados de productos.
    solution: |
      Enfoque HÍBRIDO:
      1. NLP Service extrae productos de MCP y los retorna en TextResponse.products
      2. NLP template incluye macro product_format() para guiar a Gemini
      3. Multi-Channel recibe productos estructurados para uso downstream

      Flujo:
      User → NLP → MCP → products[] → ProcessingResult{text, products}
                                                ↓
                              Multi-Channel (format_nlp_products)

      Campos de ProductData: sku, name, brand, price, description, category, image_url
    files_affected:
      - nlp-service/app/api/schemas.py (ProductData, TextResponse.products)
      - nlp-service/app/services/function_calling.py (_extract_products_from_result)
      - nlp-service/app/api/routes.py (incluir products en respuesta)
      - nlp-service/app/templates/agents/sales/base.j2 (añadir macro)
      - multi-channel-service/src/telegram_bot/templates/__init__.py (format_nlp_products)
      - multi-channel-service/src/telegram_bot/services/message_processor.py

# =============================================================================
# Patrones y Convenciones
# =============================================================================
patterns:

  commit_style:
    format: "conventional commits"
    examples:
      - "fix: correct ASR response parsing"
      - "feat: add auto-detection for audio language"
      - "docs: update webhook troubleshooting"
    co_author: "Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"

  code_quality:
    linter: ruff
    formatter: ruff format
    pre_deploy_validation: true
    command: "make deploy (incluye validación)"

  deployment:
    tool: Cloud Build
    config: cloudbuild.yaml
    quick_deploy: "make deploy-quick (sin validación)"
    full_deploy: "make deploy (con lint + format check)"

  logging:
    style: structlog
    format: "timestamp | level | message | key=value"

  templates:
    engine: Jinja2
    location: src/telegram_bot/templates/
    usage: |
      from telegram_bot.templates import templates
      templates.render_error("nlp_failed", "es")  # Error i18n
      templates.render_command("start")           # Command response
      templates.render_product_list(products, has_exact_match=True)
      templates.render_carousel_caption(product, is_exact=True)
      templates.render_document_prompt(extracted_text)
      templates.format_nlp_products(products, "es")  # Format NLP products
    add_new_language: |
      1. Create templates/messages/errors/{lang}.j2
      2. Add language code to TemplateManager.SUPPORTED_LANGUAGES

# =============================================================================
# Comandos Frecuentes
# =============================================================================
common_commands:
  deploy: "make deploy"
  deploy_quick: "make deploy-quick"
  logs: "make logs"
  logs_asr: "make logs-asr"
  logs_error: "make logs-error"
  health: "make health"
  webhook_status: "make webhook"
  webhook_reset: "make webhook-reset"
  format: "make format"
  lint: "make lint"

# =============================================================================
# Preferencias del Usuario
# =============================================================================
preferences:
  language: Spanish (comunicación), English (código/commits)
  deploy_style: Cloud Build via Makefile
  avoid:
    - No crear archivos nuevos innecesarios
    - No duplicar archivos (ej: model.py → models_simple.py)
  prefer:
    - Editar archivos existentes
    - Usar Makefile para operaciones comunes
    - Commits descriptivos con conventional commits
    - Revisar logs antes de diagnosticar

# =============================================================================
# Troubleshooting Quick Reference
# =============================================================================
troubleshooting:

  audio_not_transcribing:
    check:
      - "make logs-asr - Verificar errores del ASR"
      - "gcloud services list --enabled - Verificar speech.googleapis.com"
    common_causes:
      - API Speech-to-Text deshabilitada
      - language_hint incorrecto
      - Formato de respuesta parseado incorrectamente

  webhook_errors:
    404: "URL apunta a ngrok expirado → Reconfigurar con make webhook-reset"
    401: "Falta secret_token → Usar make webhook-reset (incluye secret)"
    403: "URL apunta a Cloud Run directo → Debe apuntar a API Gateway"

  deploy_failures:
    format_error: "make format && make deploy"
    auth_error: "gcloud auth login"
